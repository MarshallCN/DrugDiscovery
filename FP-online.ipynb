{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"FP-online.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"f4EwgcRIDagX","colab_type":"code","colab":{}},"source":["print(\"Importing modules...\")\n","import numpy as np\n","import pandas as pd\n","import scipy\n","import sklearn\n","import skmultilearn\n","from sklearn.metrics import (accuracy_score, precision_score, f1_score, recall_score, hamming_loss, zero_one_loss)\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import LinearSVC\n","from sklearn.model_selection import train_test_split\n","from skmultilearn.problem_transform import BinaryRelevance\n","from skmultilearn.problem_transform import LabelPowerset\n","from skmultilearn.problem_transform import ClassifierChain\n","print(\"...Complete\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i8_nYjXRDagh","colab_type":"code","colab":{}},"source":["def set_problem_transformation(clf, method):\n","    \"\"\"\n","    ====================================================================================\n","                                  Set Problem Transformation\n","    ====================================================================================\n","    Key arguments:\n","        clf     =  scikit-learn classifier (e.g. RandomForestClassifier())\n","        method  =  scikit-multilearn problem transformation method among the ones below:\n","        \n","                   'BR' = BinaryRelevance()\n","                   'LP' = LabelPowerset()\n","                   'CC' = ClassifierChain()\n","    ====================================================================================\n","    \"\"\"\n","    # define methods\n","    methods = {'BR' : BinaryRelevance(classifier=clf, require_dense=[True,True]),\n","               'LP' : LabelPowerset(classifier=clf, require_dense=[True,True]),\n","               'CC' : ClassifierChain(classifier=clf, require_dense=[True,True])}\n","    \n","    # set the problem transformation\n","    if method in methods.keys():\n","        pt_clf = methods[method]\n","        return pt_clf\n","    else:\n","        return str(method)+\" is not contained among the possible methods (Try to use 'BR', 'LP', or 'CC')\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HAsq1iRBDagn","colab_type":"code","colab":{}},"source":["def metrics_problem_transformation(pt_clf, X_train, y_train, X_test, y_test):\n","    \"\"\"\n","    ====================================================================================\n","                                  Test Problem Transformation\n","    ====================================================================================\n","    Key arguments:\n","        pt_clf   =  scikit-multilearn problem transformation classifier\n","        X_train  =  pandas dataframe containing the training set values\n","        y_train  =  pandas dataframe containing the training set labels\n","        X_test   =  pandas dataframe containing the test set values\n","        y_test   =  pandas dataframe containing the test set labels\n","    ====================================================================================\n","    \"\"\"    \n","    # load modules\n","    import pandas as pd\n","    from sklearn.metrics import (accuracy_score, precision_score, f1_score, recall_score, hamming_loss, zero_one_loss)\n","    \n","    # train\n","    print(\"Fitting the function...\")\n","    pt_clf.fit(X_train, y_train)\n","    print(\"...Complete\")\n","    \n","    # predict and convert\n","    print(\"Predicting the entries...\")\n","    y_pred = pt_clf.predict(X_test)\n","    print(\"...Complete\\n\")\n","    y_pred = y_pred.todense(order=None, out=None)\n","    y_pred = pd.DataFrame(y_pred, index=y_test.index.values, columns=y_test.columns.values)\n","    \n","    # metrics\n","    accuracy = sklearn.metrics.accuracy_score(y_test, y_pred)\n","    hloss = sklearn.metrics.hamming_loss(y_test, y_pred)\n","    zero_one_loss = sklearn.metrics.zero_one_loss(y_test, y_pred)\n","    micro_precision = sklearn.metrics.precision_score(y_test, y_pred, average='micro')\n","    weighted_precision = sklearn.metrics.precision_score(y_test, y_pred, average='weighted')\n","    micro_recall = sklearn.metrics.recall_score(y_test, y_pred, average='micro')\n","    weighted_recall = sklearn.metrics.recall_score(y_test, y_pred, average='weighted')\n","    macro_f1 = sklearn.metrics.f1_score(y_test, y_pred, average='macro')\n","    micro_f1 = sklearn.metrics.f1_score(y_test, y_pred, average='micro')\n","    weighted_f1 = sklearn.metrics.f1_score(y_test, y_pred, average='weighted')\n","    #report =  sklearn.metrics.classification_report(y_test, y_pred)\n","    \n","    # list metrics and round them\n","    metrics = [accuracy, hloss, zero_one_loss, micro_recall, weighted_recall,\n","              micro_precision, weighted_precision, macro_f1, micro_f1, weighted_f1]\n","    rnd_metrics =  [round(x,2) for x in metrics]\n","    \n","    # return rnd_metrics\n","    #print (pt_clf)\n","   # print (rnd_metrics)\n","   # print ()\n","    return metrics\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4HDsCH2VDagv","colab_type":"code","colab":{}},"source":["FINGERPRINT = \"Top15\" # Top5, Top10, Top15, Top20, Top25, Top50, FCFP0, FCFP2, FCFP4\n","FRINGERPRINTS = [\"Top20\", \"Top25\", \"Top50\"]\n","for FINGERPRINT in FRINGERPRINTS:\n","    PATH = \"E:/Google 云端硬盘/2019- Zehao (1)/{0}_Fingerprint\".format(FINGERPRINT)\n","\n","    print(\"Loading datasets...\")\n","    df = pd.read_csv(\"{0}/{1}.csv.gz\".format(PATH,FINGERPRINT), compression='gzip')\n","\n","    #X = df[df.columns[list(df.columns).index('bitvector0'):]] \n","    #y = df[df.columns[:list(df.columns).index('bitvector0')]] \n","    X = df.filter(like='bit', axis=1)  #select rows containing 'bit' \n","    y = df[df.columns.drop(list(df.filter(regex='bit|StringFP|row ID')))] #remove columns containing 'bit' and RowID\n","\n","    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=111)\n","\n","    from skmultilearn.model_selection import iterative_train_test_split\n","    X_train, y_train, X_test, y_test = iterative_train_test_split(np.array(X), np.array(y), test_size = 0.2)\n","\n","    #stratified sampling http://scikit.ml/stratification.html\n","    y_train = pd.DataFrame(y_train)\n","    y_test = pd.DataFrame(y_test)\n","    y_test.columns, y_train.columns = y.columns,y.columns\n","    X_train = pd.DataFrame(X_train)\n","    X_test = pd.DataFrame(X_test)\n","    X_test.columns, X_train.columns = X.columns,X.columns\n","    print(\"...Complete\")\n","\n","    # define rf classifier\n","    rf = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, \n","                                min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n","                                max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, \n","                                min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=4, \n","                                random_state=11, verbose=0, warm_start=False, class_weight=None)\n","\n","    # define svm classifier\n","    svm = LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, \n","                    C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, \n","                    class_weight=None, verbose=0, random_state=11, max_iter=10000)\n","\n","    methods_to_test = ['BR', 'CC', 'LP']\n","    classifiers_to_test = [rf, svm]\n","    error = []\n","    for c in classifiers_to_test:\n","        for m in methods_to_test:\n","            try:\n","                pt_clf = set_problem_transformation(c, m)\n","                metrics = metrics_problem_transformation(pt_clf, X_train, y_train, X_test, y_test)\n","                # append metrics into file\n","                f = open(\"{0}/{1}-metrics.csv\".format(PATH,FINGERPRINT), \"a+\")\n","                fr = open(\"{0}/{1}-metrics.csv\".format(PATH,FINGERPRINT), \"r\")\n","                if(sum(1 for line in fr)==0):\n","                    f.write(\"method,classifier,accuracy, hloss, zero_one_loss, micro_recall, weighted_recall, micro_precision, weighted_precision, macro_f1, micro_f1, weighted_f1\"+\"\\n\")\n","                fr.close()\n","                f.write(','.join([m,str(c).split('(')[0],','.join(map(str, [round(x,2) for x in metrics]))])+\"\\n\")\n","                f.close()\n","            except Exception as e:\n","                error.append(e)"],"execution_count":0,"outputs":[]}]}